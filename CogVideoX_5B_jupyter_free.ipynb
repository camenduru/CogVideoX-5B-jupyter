{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/CogVideoX-5B-jupyter/blob/main/CogVideoX_5B_jupyter_free.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "!pip install xformers==0.0.27.post2 diffusers==0.30.1 accelerate==0.33.0 sentencepiece==0.2.0 moviepy==1.0.3 optimum-quanto==0.2.4 bitsandbytes==0.43.3\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/vdo/CogVideoX-5b/raw/main/vae/config.json -d /content/CogVideoX-5b/vae -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/vdo/CogVideoX-5b/resolve/main/vae/diffusion_pytorch_model.safetensors -d /content/CogVideoX-5b/vae -o diffusion_pytorch_model.safetensors\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/vdo/CogVideoX-5b/raw/main/scheduler/scheduler_config.json -d /content/CogVideoX-5b/scheduler -o scheduler_config.json\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/vdo/CogVideoX-5b/raw/main/tokenizer/added_tokens.json -d /content/CogVideoX-5b/tokenizer -o added_tokens.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/vdo/CogVideoX-5b/raw/main/tokenizer/special_tokens_map.json -d /content/CogVideoX-5b/tokenizer -o special_tokens_map.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/vdo/CogVideoX-5b/resolve/main/tokenizer/spiece.model -d /content/CogVideoX-5b/tokenizer -o spiece.model\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/vdo/CogVideoX-5b/raw/main/tokenizer/tokenizer_config.json -d /content/CogVideoX-5b/tokenizer -o tokenizer_config.json\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/raw/main/text_encoder/config.json -d /content/CogVideoX-5b/text_encoder -o config.json \n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/resolve/main/text_encoder/model-00001-of-00003.safetensors -d /content/CogVideoX-5b/text_encoder -o model-00001-of-00003.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/resolve/main/text_encoder/model-00002-of-00003.safetensors -d /content/CogVideoX-5b/text_encoder -o model-00002-of-00003.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/resolve/main/text_encoder/model-00003-of-00003.safetensors -d /content/CogVideoX-5b/text_encoder -o model-00003-of-00003.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/raw/main/text_encoder/model.safetensors.index.json -d /content/CogVideoX-5b/text_encoder -o model.safetensors.index.json\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/raw/main/transformer/config.json -d /content/CogVideoX-5b/transformer -o config.json \n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/resolve/main/transformer/diffusion_pytorch_model-00001-of-00003.safetensors  -d /content/CogVideoX-5b/transformer -o diffusion_pytorch_model-00001-of-00003.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/resolve/main/transformer/diffusion_pytorch_model-00002-of-00003.safetensors  -d /content/CogVideoX-5b/transformer -o diffusion_pytorch_model-00002-of-00003.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/resolve/main/transformer/diffusion_pytorch_model-00003-of-00003.safetensors  -d /content/CogVideoX-5b/transformer -o diffusion_pytorch_model-00003-of-00003.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/cogvideox-5b-float16/raw/main/transformer/diffusion_pytorch_model.safetensors.index.json  -d /content/CogVideoX-5b/transformer -o diffusion_pytorch_model.safetensors.index.json\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "from typing import Union, List\n",
        "import PIL.Image\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from diffusers.image_processor import VaeImageProcessor\n",
        "from diffusers.utils import export_to_video\n",
        "import moviepy.editor as mp\n",
        "from diffusers import AutoencoderKLCogVideoX, CogVideoXTransformer3DModel, CogVideoXDDIMScheduler, CogVideoXPipeline\n",
        "from transformers import T5EncoderModel, T5Tokenizer\n",
        "\n",
        "def convert_to_gif(video_path):\n",
        "    clip = mp.VideoFileClip(video_path)\n",
        "    clip = clip.set_fps(8)\n",
        "    clip = clip.resize(height=240)\n",
        "    gif_path = video_path.replace(\".mp4\", \".gif\")\n",
        "    clip.write_gif(gif_path, fps=8)\n",
        "    return gif_path\n",
        "\n",
        "def save_video(tensor: Union[List[np.ndarray], List[PIL.Image.Image]], fps: int = 8):\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    video_path = f\"{timestamp}.mp4\"\n",
        "    export_to_video(tensor, video_path, fps=fps)\n",
        "    return video_path\n",
        "\n",
        "transformer = CogVideoXTransformer3DModel.from_pretrained(\"/content/CogVideoX-5b\", subfolder=\"transformer\", torch_dtype=torch.float16)\n",
        "# transformer = CogVideoXTransformer3DModel.from_pretrained(\"/content/CogVideoX-5b\", subfolder=\"transformer\", quantization_config=quantization_config)\n",
        "print(next(transformer.parameters()).device)\n",
        "print(next(transformer.parameters()).dtype)\n",
        "\n",
        "text_encoder = T5EncoderModel.from_pretrained(\"/content/CogVideoX-5b\", subfolder=\"text_encoder\", torch_dtype=torch.float16)\n",
        "# text_encoder = T5EncoderModel.from_pretrained(\"THUDM/CogVideoX-5b\", subfolder=\"text_encoder\", device_map=\"auto\", quantization_config=quantization_config)\n",
        "print(next(text_encoder.parameters()).device)\n",
        "print(next(text_encoder.parameters()).dtype)\n",
        "\n",
        "vae = AutoencoderKLCogVideoX.from_pretrained(\"/content/CogVideoX-5b\", subfolder=\"vae\", torch_dtype=torch.float16)\n",
        "print(next(vae.parameters()).device)\n",
        "print(next(vae.parameters()).dtype)\n",
        "\n",
        "scheduler = CogVideoXDDIMScheduler.from_pretrained(\"/content/CogVideoX-5b\", subfolder=\"scheduler\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"/content/CogVideoX-5b\", subfolder=\"tokenizer\")\n",
        "\n",
        "pipe = CogVideoXPipeline(transformer=transformer, text_encoder=text_encoder, vae=vae, tokenizer=tokenizer, scheduler=scheduler)\n",
        "\n",
        "pipe.enable_model_cpu_offload()\n",
        "pipe.enable_sequential_cpu_offload()\n",
        "pipe.vae.enable_slicing()\n",
        "pipe.vae.enable_tiling()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"A golden retriever, sporting sleek black sunglasses, with its lengthy fur flowing in the breeze, sprints playfully across a rooftop terrace, recently refreshed by a light rain. The scene unfolds from a distance, the dog's energetic bounds growing larger as it approaches the camera, its tail wagging with unrestrained joy, while droplets of water glisten on the concrete behind it. The overcast sky provides a dramatic backdrop, emphasizing the vibrant golden coat of the canine as it dashes towards the viewer.\"\n",
        "seed = 0\n",
        "\n",
        "if seed == 0:\n",
        "    random.seed(int(time.time()))\n",
        "    seed = random.randint(0, 18446744073709551615)\n",
        "print(seed)\n",
        "\n",
        "with torch.inference_mode():\n",
        "    video_pt = pipe(\n",
        "        prompt=prompt,\n",
        "        num_videos_per_prompt=1,\n",
        "        num_inference_steps=50,\n",
        "        num_frames=49,\n",
        "        use_dynamic_cfg=True,\n",
        "        output_type=\"pt\",\n",
        "        guidance_scale=7.0,\n",
        "        generator=torch.Generator(device=\"cpu\").manual_seed(seed),\n",
        "    ).frames\n",
        "\n",
        "batch_size = video_pt.shape[0]\n",
        "batch_video_frames = []\n",
        "for batch_idx in range(batch_size):\n",
        "    pt_image = video_pt[batch_idx]\n",
        "    pt_image = torch.stack([pt_image[i] for i in range(pt_image.shape[0])])\n",
        "\n",
        "    image_np = VaeImageProcessor.pt_to_numpy(pt_image)\n",
        "    image_pil = VaeImageProcessor.numpy_to_pil(image_np)\n",
        "    batch_video_frames.append(image_pil)\n",
        "\n",
        "video_path = save_video(batch_video_frames[0], fps=math.ceil((len(batch_video_frames[0]) - 1) / 6))\n",
        "gif_path = convert_to_gif(video_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
